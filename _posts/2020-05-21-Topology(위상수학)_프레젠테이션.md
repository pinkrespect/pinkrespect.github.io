---
title: Topology(위상 수학) 첫 프레젠테이션 
published: true
---

## [](#header-1)서론
회사에서 어떤 분이 논문을 주셨는데, Topology와 Data의 연관성과 함께 Deep Learning의 Neural Network를 위상 수학으로 관측 가능한지에 대한
논문이였다.
<br>

항상 블랙박스로만 알고 있었는데, 그렇지 않다는 것을 알게 되어서 꽤나 충격이였고, 그 배움의 기쁨을 기록하고자 한다.
<br>

## [](#header-2)참고 논문
만일, 군/환/체(Group/Ring/Field)에 대한 기본 개념이 없다면,
[여기](https://www.researchgate.net/profile/Nek_Valous/publication/333045404_Computational_Topology_for_Biomedical_Image_and_Data_Analysis_Theory_and_Applications/links/5d559a1f299bf151bad6decf/Computational-Topology-for-Biomedical-Image-and-Data-Analysis-Theory-and-Applications.pdf)에 있는 훌륭한 책으로 공부할 수 있다.
<br>

만일, 군/환/체에 대한 기본 개념은 있으나 위상 수학에 대해 공부한 적이
없다면, [여기](https://www.researchgate.net/publication/220692408_Computational_Topology_An_Introduction)에서 기초를 공부할 수 있다.
<br>

참고 논문은
*   [Boolean neural Nets are observable](https://core.ac.uk/download/pdf/81926832.pdf)
*   [Topology and data](http://www.ayasdi.com/wp-content/uploads/2015/02/Topology_and_Data.pdf)
<br>

참고 영상은
*   [3Brown1Blue - Who cares about topology? (Inscribed rectangle problem)](https://www.youtube.com/watch?v=AmgkSdhK4K8)
<br>

위 내용을 참고해서 프레젠테이션을 보면 조금 더 이해가 쉽다.


## [](#header-3)프레젠테이션
### [](#header-3-1)기초 지식
물론 위의 훌륭한 텍스트와 영상을 다 보고 오셨다면, 이 부분은 넘어가도 괜찮다.<br>

그렇지만 저 위의 내용은 너무 길고 장엄하고, 또 수학적 지식이 충분치 않다면 이해하기 어려울 수도 있으므로, 회사에서 진행한 프레젠테이션에서는 위의 간략한 내용을 상상 가능하고 수학적으로는 엄밀하지 않은 정도로 다뤘다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/1.png)

표지는 직접 그렸다. 가능한 이 것이 어렵지 않게 다가갔으면 했다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/2.png)

단순한 목차인데, 여기 또 숨은 비밀이 있다.<br>
처음에는 목차를 엄청 잘게 자를까 하다가, 그랬다가는 사람들이 다 도망갈 것 같아서(..)<br>
잘게 자른건 보여주지 않고 그냥 대목록만 보여주는 것이 낫겠다는 생각이 들었다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/3.png)

그리고 또 쓰다보니 아무래도 수학적으로 엄밀하게 상상하시는 분들에게는 양해의 말을 구해야겠다 싶어서,<br>
처음 여는 말로 양해의 말씀을 넣었다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/4.png)

배우는 동안 머리 속에 있는 공간에 이런 저런 일을 해볼 수 있어서 즐거웠기 때문에, 같이 즐거웠으면 좋겠다는 마음을 담았다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/5.png)

나처럼 수학을 전공하지 않은 사람이 알고 있는 위상 수학의 기본적인 지식을 소개한다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/6.png)

그리고 위상수학에서 공간을 어떤 식으로 닮았다/다르다고 하는지, 또 기하학적인 공간과 무엇이 다른지 소개했다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/7.png)

일단 2차원 공간에 이런 선으로 이어져 있어 연속성이 있는 공간이 있다고 가정하자.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/8.png)

연속성이 있는 선형 공간에서는 어디에 점을 찍어도 사각형을 만들 수 있는데,<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/9.png)

사각형을 만들 수 있는 조건은 다음과 같다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/10.png)

이런 식으로 정사각형도 그릴 수 있으며,<br>
이제 차원을 확장시켜 이 도형을 다른 모습으로 표현하기 위해 z축으로 수선의 발을 내려본다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/12.png)

a라는 점에서부터 d라는 점을 이어 그 중앙점 __M__으로 내려오는 거리 __D__만큼의 직교하는 선이 있다고 하면<br>
이제 차원이 확장되어 __f(A, B) = (x, y, z)__라고 표현할 수 있다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/13.png)

또한 이 공간은 연속적이기 때문에, 좌표로 표현할 수 없다. 축이 정해져있지 않기 때문이다.<br>
따라서 이 공간의 어떤 점들은 모두 집합(set)으로 표현 가능하다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/14.png)

이제 선을 잘라 한 직선으로 펼쳐보자.<br>
펼친 선을 동일한 축으로 늘려 x, y축으로 표현해보면 아래 그림처럼 한 그래프 공간에 두 점이 찍히게 된다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/16.png)

또한 아까 잘라낸 선은 0->1의 방향성이 있기 때문에 위 그래프 또한 이 그림처럼 표현 가능하다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/17.png)

이제 다른 공간에 같은 점을 표현하기 위해, 공간을 같은 축끼리 접어본다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/18.png)

파란 축끼리 둥글게 말면, 이제 도넛 모양이 등장한다!<br>
하지만 아직도 축이 두개로, 동일한 점이 두 번 나타난다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/19.png)

이제 다시 축이 동일한 2차원 그래프로 돌아가서, 이 그래프에서 어떻게 해야할지 고민해보자.<br>
축이 동일한 방향이므로, 절반을 접을 수 있다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/20.png)

여전히 축이 두개이기 때문에, 축을 없애기 위해서 한번 더 잘라서 붙인다.<br>
그러면 새로운 축과 함께 기존의 축이 남아있는데,<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/21.png)

이 새로운 축을 서로 비틀어서 연결해주면, 축이 하나인 공간이 나타난다.<br>
뫼비우스의 띠 모양을 표현하려고 했는데, 그림 실력이 형편없다.<br>
이제 드디어 기존 공간과 1:1 대응 가능한 새로운 공간이 생겼다.<br>


### [](#Header-3-2) 데이터의 관측 가능성

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/22.png)

데이터의 관측 가능성을 설명하기 위해 여기까지 설명했다.<br>
여태 해온 것보다 훨씬 압축되어있고, 필요한 내용만 담았기 때문에 사실 설명하면서도,<br>
모두가 따라올 수 있을지 걱정을 많이 했는데, 이 논문을 주신 분께서 검토해 주시면서<br>
이정도면 괜찮을거라고 해서 안심했더니 그러면 안됐다(..)<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/23.png)

위의 공간에서 선을 점점 좁혀보면, 결국 남는(의미있는) 공간은 두 개만 남게 된다.<br>
결국 어떤 공간 위의 선은 어떤 특정한 모양을 남겨야 의미가 있다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/24.png)

이 홀이나 빈 공간의 수를 베티 수라고 하는데, 위 그림에서는 현재 베티 수가 3이다.<br>
다만 작은 두개의 홀은 데이터의 오류로 발생한 홀이라고 가정하면,<br>
데이터의 매개변수(Parameter) 조절로 보정 가능하고, 남게되는 베티 수는 2가 된다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/25.png)

만일 이전 슬라이드의 공간을 모두 포함하는 원을 그려본다고 하면,<br>
이 슬라이드의 그림처럼 모든 공간의 연속성을 포함하는 원을 그릴 수 있다.<br>
이를 단순화시켜서 선으로 그려보면, A-C-B, Natural Covering 할 수 있다.<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/26.png)

따라서 이전 슬라이드에 표현된 연속적인 데이터를, 위상수학적으로 쪼갤 수 있으며,<br>
매개변수를 통해 조절 가능하다.<br>
연속적인 데이터이기 때문에 어떤 조절이 불가능하다고 생각했었는데, 어쩌면 Neural Network도 관측 가능하지 않을까?<br>

![](https://raw.githubusercontent.com/pinkrespect/pinkrespect.github.io/master/_posts/topology_presentation_01/28.png)

이것은 초반에 참고 자료로 소개한 Boolean Neural Nets are observable 논문에서도 확인할 수 있다.<br>
(물론 Boolean 말고 CNN이나 다른 신경망도 해석 가능하다는 논문이 많이 있다.)<br>
이 부분은 논문을 읽고 이해하는 편이 빠르므로, 한 번 읽어보는 편이 좋고,<br>
그게 아니면 그냥 이 슬라이드로 이해하는 것이 좋겠다.<br>

## [](#Header-4) 마치며

저자에게 데이터 흐름을 통해 신경망의 레이어를 관측할 수 있는 코드가 있는 듯 한데,<br>
그걸 얻을 수가 없어 아쉽다. 메일이라도 보내볼까.<br>

<br>

수학계에서는 이미 1994년도부터 신경망의 관측 가능성을 위상 수학으로 해결 가능하다고 보고 있었는데,<br>
너무 섣불리 블랙박스라고 단정지은건 아닌지, 고민이 된다.<br>

